{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUvsR-mWBoNS"
   },
   "source": [
    "# Develop a Fake or Real Discriminator\n",
    "\n",
    "In this notebook, we walk though the steps of developing a machine learning model that is trained to distinguish between fake (=synthetic) and real records. The model's ability to correctly dicriminate between these on an unseen holdout can serve us as another helpful quality criteria for the generated synthetic data. The more realistic those synthetic records are, the harder it will be for any discriminator to tell these apart from the real records.\n",
    "\n",
    "In order to make the analysis more interesting, we intentionally create synthetic data of lower quality, by limiting the training samples to only a thousand records. Otherwise, the discriminator would not be able to find much signal, if the synthesizer, like MOSTLY AI, is of very high quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKRa93uuSqZS"
   },
   "source": [
    "## Synthesize Data via MOSTLY AI\n",
    "\n",
    "For this tutorial, we will be using again the UCI Adult Income [[1](#refs)] dataset, which consists of 48842 records across 15 attributes.\n",
    "\n",
    "1. Download `census.csv` from [here](./census.csv).\n",
    "\n",
    "2. Synthesize `census.csv` via [MOSTLY AI](https://mostly.ai/), but limit training samples to 1000 records.\n",
    "\n",
    "<img src='./screen1.png' width=\"400px\"/>\n",
    "\n",
    "3. Once the job has finished, download the generated synthetic data as CSV file to your computer.\n",
    "\n",
    "4. Upload the generated synthetic data to this Notebook via executing the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "id": "W4IDNOIyPW7L",
    "outputId": "413106b9-de23-441b-ae27-f6efe45085a6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running in LOCAL mode\n",
      "adapt `syn_file_path` to point to your generated synthetic data file\n",
      "read synthetic data with 48,842 records and 14 attributes\n"
     ]
    }
   ],
   "source": [
    "# upload synthetic dataset\n",
    "import pandas as pd\n",
    "try:\n",
    "    # check whether we are in Google colab\n",
    "    from google.colab import files\n",
    "    print(\"running in COLAB mode\")\n",
    "    repo = 'https://github.com/mostly-ai/mostly-tutorials/raw/dev/train-synthetic-test-real'\n",
    "    import io\n",
    "    uploaded = files.upload()\n",
    "    syn = pd.read_csv(io.BytesIO(list(uploaded.values())[0]))\n",
    "    print(f\"uploaded synthetic data with {syn.shape[0]:,} records and {syn.shape[1]:,} attributes\")\n",
    "except:\n",
    "    print(\"running in LOCAL mode\")\n",
    "    repo = '.'\n",
    "    print(\"adapt `syn_file_path` to point to your generated synthetic data file\")\n",
    "    syn_file_path = './census-synthetic-1k.csv'\n",
    "    syn = pd.read_csv(syn_file_path)\n",
    "    print(f\"read synthetic data with {syn.shape[0]:,} records and {syn.shape[1]:,} attributes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OgvJ0XoWTHoX"
   },
   "source": [
    "## Train Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Rl6-YXB_e0Ac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def prepare_xy(df, target_col, target_val):\n",
    "    # split target variable `y`\n",
    "    y = (df[target_col]==target_val).astype(int)\n",
    "    # convert strings to categoricals, and all others to floats\n",
    "    str_cols = [col for col in df.select_dtypes(['object', 'string']).columns if col != target_col]\n",
    "    for col in str_cols:\n",
    "        df[col] = pd.Categorical(df[col])\n",
    "    cat_cols = [col for col in df.select_dtypes('category').columns if col != target_col]\n",
    "    num_cols = [col for col in df.select_dtypes('number').columns if col != target_col]\n",
    "    for col in num_cols:\n",
    "        df[col] = df[col].astype('float')\n",
    "    X = df[cat_cols + num_cols]\n",
    "    return X, y\n",
    "\n",
    "def train_model(X, y):\n",
    "    cat_cols = list(X.select_dtypes('category').columns)\n",
    "    X_trn, X_val, y_trn, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    ds_trn = lgb.Dataset(X_trn, label=y_trn, categorical_feature=cat_cols, free_raw_data=False)\n",
    "    ds_val = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_cols, free_raw_data=False)\n",
    "    model = lgb.train(\n",
    "        params={\n",
    "            'metric': 'auc',  \n",
    "            'objective': 'binary'\n",
    "        },\n",
    "        train_set=ds_trn,\n",
    "        valid_sets=[ds_val],\n",
    "        callbacks=[early_stopping(5)],\n",
    "    )\n",
    "    return model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KRkpufuwougw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "FAKE    48842\n",
       "REAL    48842\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate FAKE and REAL data together\n",
    "tgt = pd.read_csv(f'{repo}/census.csv')\n",
    "df = pd.concat([\n",
    "    tgt.assign(split='REAL'),\n",
    "    syn.assign(split='FAKE'),\n",
    "], axis=0)\n",
    "df.groupby('split').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "i0rxFaBctmYD",
    "outputId": "5f93c4c1-5042-4798-8160-1c691fa2bafc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# take a 20% holdout dataset aside for evaluation\n",
    "trn, hol = train_test_split(df, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "sStO_jULn8kL",
    "outputId": "13475d7e-d388-4883-ea01-7b1592919223",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# train the discriminator on the remaining 80% training dataset\n",
    "X_trn, y_trn = prepare_xy(trn, 'split', 'FAKE')\n",
    "model = train_model(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "BKJ0R-HTr9bt",
    "outputId": "a711e24e-3384-4586-ecab-964967693ea4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score the model on the holdout dataset, assigning a propability to each record on whether it's FAKE or REAL\n",
    "X_hol, y_hol = prepare_xy(hol, 'split', 'FAKE')\n",
    "hol.insert(0, 'is_fake', model.predict(X_hol).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXiu9W3469Sc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc = roc_auc_score(y_hol, hol.is_fake)\n",
    "probs_df = pd.concat([\n",
    "    pd.Series(hol.is_fake, name='probability').reset_index(drop=True),\n",
    "    pd.Series(y_hol, name='target').reset_index(drop=True)\n",
    "], axis=1)\n",
    "fig = sns.displot(data=probs_df, x='probability', hue='target', bins=20, palette=['#008CFB', '#FF004F'])\n",
    "fig = plt.title(f\"Holdout ROC AUC: {auc:.3f}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SZUfYStL7axE"
   },
   "source": [
    "As you can see from above chart, the discriminator has learned to pick up some signals that allow it with a varying level of confidence to determine whether a record is FAKE or REAL. \n",
    "\n",
    "The AUC can be interpreted as the percentage of cases, where the discriminator is able to correctly spot the FAKE record, given a set of a FAKE and a REAL record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display 5 records that seem very FAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hol.sort_values('is_fake').tail(n=100).sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these cases, it is the mismatch between `education` and `education_num` that gives away the fact that these are FAKE. In the original data, education level `Assoc-acdm` was mapped to education number 12, whereas in the synthetic data we see various other numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.crosstab(tgt.education, tgt.education_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.crosstab(syn.education, syn.education_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### display 5 records that seem very REAL\n",
    "\n",
    "I.e. these are type of records, that the synthesizer has apparently failed to create. Thus, as they are then absent from the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hol.sort_values('is_fake').head(n=100).sample(n=5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQMOiU1Bv6W4"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial has shown how to train a discriminator that is set out to distinguish between RAKE and REAL records. The better the quality of the generated synthetic data, the less likely the discriminator (as well as we humnans) can tell them apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further exercises\n",
    "\n",
    "In addition to walking through the above instructions, we suggest..\n",
    "* measuring the Discriminator's AUC if more training samples are used\n",
    "* using a different dataset, eg. the UCI bank-marketing dataset [[2](#refs)]\n",
    "* using a different ML model for the discriminator, eg. a RandomForest model [[3](#refs)]\n",
    "* using a different synthesizer, eg. SynthCity, SDV, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UW5ntiUB18yP"
   },
   "source": [
    "## References<a class=\"anchor\" name=\"refs\"></a>\n",
    "\n",
    "1. https://archive.ics.uci.edu/ml/datasets/adult\n",
    "1. https://archive.ics.uci.edu/ml/datasets/bank+marketing\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
